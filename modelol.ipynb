{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47944 entries, 0 to 47943\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   yorum   47944 non-null  object \n",
      " 1   puan    47944 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('sonyorum.csv')\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text before filtering:\n",
      "ouch...junior is angryð#got7 #junior #yugyo..., @user\n",
      "\n",
      "\n",
      "Text after filtering:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ouchjunior is angrygot7 junior yugyo '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "## texti temizliyoruz\n",
    "print(\"Text before filtering:\\nouch...junior is angryð#got7 #junior #yugyo..., @user\")\n",
    "print(\"\\n\\nText after filtering:\")\n",
    "re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \"\",\"ouch...junior is angryð#got7 #junior #yugyo..., @user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yorum</th>\n",
       "      <th>puan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beğendim 10 numara 8-9 bilgisayara kadar gider...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urun kalitesi on numara bes yildiz</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ürün güzel ama şarj kablosu kalitesiz</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ürünü kartona sarıp göndermek yerine streçe sa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dakikalarca uğraşmama rağmen aracım da sadece ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ürün harika sadece temizlemesi sorun..</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kılıf fiyatına göre gayet iyi gönül rahatlığıy...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sadece oyuncular için değil ofiste çalışanlar ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Güzel ve kaliteli ürün. Kargodaki özende olduk...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.5 yil once ayni urunden almistim. digerinin ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               yorum  puan\n",
       "0  Beğendim 10 numara 8-9 bilgisayara kadar gider...   1.0\n",
       "1                 Urun kalitesi on numara bes yildiz   1.0\n",
       "2              ürün güzel ama şarj kablosu kalitesiz   1.0\n",
       "3  Ürünü kartona sarıp göndermek yerine streçe sa...   0.0\n",
       "4  Dakikalarca uğraşmama rağmen aracım da sadece ...   0.0\n",
       "5             Ürün harika sadece temizlemesi sorun..   1.0\n",
       "6  Kılıf fiyatına göre gayet iyi gönül rahatlığıy...   1.0\n",
       "7  Sadece oyuncular için değil ofiste çalışanlar ...   1.0\n",
       "8  Güzel ve kaliteli ürün. Kargodaki özende olduk...   1.0\n",
       "9  1.5 yil once ayni urunden almistim. digerinin ...   1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gereksiz sık kullanılan kelimelerin (stop-words) atılması\n",
    "def remove_stopwords(df_fon):\n",
    "    stopwords = open('turkce-stop-words', 'r').read().split()\n",
    "    df_fon['stopwords_removed'] = list(map(lambda doc:\n",
    "        [word for word in doc if word not in stopwords], df_fon['yorum']))\n",
    "\n",
    "remove_stopwords(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[\"yorum\"],train_data[\"puan\"], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30637    Kia cerato 2006 model aracim için kullandim gü...\n",
      "39623    Kaliteli  aleminyum ürün kurulumu kolay ellbet...\n",
      "5082                            guzel ses veriyor ve rahat\n",
      "41726    Ürün sorunsuzca geldi. Hediye için de teşekkür...\n",
      "35025                            Kullanıyorum. Gayet güzel\n",
      "Name: yorum, dtype: object\n",
      "\n",
      "\n",
      "X_train shape:  (38355,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "print('\\n\\nX_train shape: ', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_tfidf = transformer.fit_transform(x_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38355, 41200)\n",
      "(38355, 41200)\n"
     ]
    }
   ],
   "source": [
    "#EGİTİM SAYILARINI ÖGRENİYORUZ\n",
    "print(x_train_counts.shape)\n",
    "print(x_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_counts = count_vect.transform(x_test)\n",
    "x_test_tfidf = transformer.transform(x_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9589, 41200)\n",
      "(9589, 41200)\n"
     ]
    }
   ],
   "source": [
    "#TEST SAYILARINI ÖĞRENİYORUZ\n",
    "print(x_test_counts.shape)\n",
    "print(x_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1=LogisticRegression()\n",
    "model1.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predLR=model1.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 493  481]\n",
      " [  26 8589]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "c_m = confusion_matrix(y_test,predLR)\n",
    "print(c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9471269162582125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.5061601642710473\n",
      "precision =  0.9499036608863198\n",
      "F1_score =  0.6604152712659075\n"
     ]
    }
   ],
   "source": [
    "tp,fn,fp,tn = c_m[0][0],c_m[0][1],c_m[1][0],c_m[1][1]\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1score = 2 * (recall * precision) / (recall + precision)\n",
    "print(\"recall = \",recall)\n",
    "print(\"precision = \", precision)\n",
    "print(\"F1_score = \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.51      0.66       974\n",
      "         1.0       0.95      1.00      0.97      8615\n",
      "\n",
      "    accuracy                           0.95      9589\n",
      "   macro avg       0.95      0.75      0.82      9589\n",
      "weighted avg       0.95      0.95      0.94      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predLR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)kötü\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)berbat\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)rezil\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)f\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model1.predict(count_vect.transform([yorum])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model2=DecisionTreeClassifier()\n",
    "model2.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 609  365]\n",
      " [ 264 8351]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predDT=model2.predict(x_test_tfidf)\n",
    "c_m1 = confusion_matrix(y_test,predDT)\n",
    "print(c_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344040045885911"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predDT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.6252566735112937\n",
      "precision =  0.697594501718213\n",
      "F1_score =  0.6594477531131564\n"
     ]
    }
   ],
   "source": [
    "tp,fn,fp,tn = c_m1[0][0],c_m1[0][1],c_m1[1][0],c_m1[1][1]\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1score = 2 * (recall * precision) / (recall + precision)\n",
    "print(\"recall = \",recall)\n",
    "print(\"precision = \", precision)\n",
    "print(\"F1_score = \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.63      0.66       974\n",
      "         1.0       0.96      0.97      0.96      8615\n",
      "\n",
      "    accuracy                           0.93      9589\n",
      "   macro avg       0.83      0.80      0.81      9589\n",
      "weighted avg       0.93      0.93      0.93      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predDT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)kötü\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)berbat\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)aşırı iyi\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)f\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model2.predict(count_vect.transform([yorum])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model3=SVC()\n",
    "model3.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSVC=model3.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 546  428]\n",
      " [  23 8592]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c_m2 = confusion_matrix(y_test,predSVC)\n",
    "print(c_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529669412868912"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.5605749486652978\n",
      "precision =  0.9595782073813708\n",
      "F1_score =  0.7077122488658457\n"
     ]
    }
   ],
   "source": [
    "tp,fn,fp,tn = c_m2[0][0],c_m2[0][1],c_m2[1][0],c_m2[1][1]\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1score = 2 * (recall * precision) / (recall + precision)\n",
    "print(\"recall = \",recall)\n",
    "print(\"precision = \", precision)\n",
    "print(\"F1_score = \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.56      0.71       974\n",
      "         1.0       0.95      1.00      0.97      8615\n",
      "\n",
      "    accuracy                           0.95      9589\n",
      "   macro avg       0.96      0.78      0.84      9589\n",
      "weighted avg       0.95      0.95      0.95      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)kötü\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)çirkin\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)en iyi\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)f\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model3.predict(count_vect.transform([yorum])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model4 = RandomForestClassifier(n_estimators=200)\n",
    "model4.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predRF = model4.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 525  449]\n",
      " [  33 8582]]\n"
     ]
    }
   ],
   "source": [
    "c_m3 = confusion_matrix(y_test,predRF)\n",
    "print(c_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497340702888727"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.5390143737166324\n",
      "precision =  0.9408602150537635\n",
      "F1_score =  0.6853785900783289\n"
     ]
    }
   ],
   "source": [
    "tp,fn,fp,tn = c_m3[0][0],c_m3[0][1],c_m3[1][0],c_m3[1][1]\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1score = 2 * (recall * precision) / (recall + precision)\n",
    "print(\"recall = \",recall)\n",
    "print(\"precision = \", precision)\n",
    "print(\"F1_score = \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.54      0.69       974\n",
      "         1.0       0.95      1.00      0.97      8615\n",
      "\n",
      "    accuracy                           0.95      9589\n",
      "   macro avg       0.95      0.77      0.83      9589\n",
      "weighted avg       0.95      0.95      0.94      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)iyi\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)kötü\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)çirkin\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)f\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model4.predict(count_vect.transform([yorum])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [] \n",
    "training = [] \n",
    "test = [] \n",
    "scores = {} \n",
    "  \n",
    "for k in range(2, 10): \n",
    "    model5 = KNeighborsClassifier(n_neighbors = k) \n",
    "    model5.fit(x_train_tfidf,y_train) \n",
    "  \n",
    "    #training_score = clf.score(x_train_tfidf,y_train) \n",
    "    predKNN = model5.predict(x_test_tfidf)\n",
    "    test_score = model5.score(x_test_tfidf, y_test) \n",
    "    K.append(k) \n",
    "  \n",
    "    #training.append(training_score) \n",
    "    test.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  91  883]\n",
      " [   6 8609]]\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "[0.9239753884659506, 0.9109396183126499, 0.8819480654917092, 0.9062467410574617, 0.9024924392533111, 0.9076024611534049, 0.9068724580248201, 0.9072896026697257]\n"
     ]
    }
   ],
   "source": [
    "c_m4 = confusion_matrix(y_test,predKNN)\n",
    "print(c_m4)\n",
    "\n",
    "print(\"\\n\\nAccuracy:\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.09342915811088295\n",
      "precision =  0.9381443298969072\n",
      "F1_score =  0.1699346405228758\n"
     ]
    }
   ],
   "source": [
    "tp,fn,fp,tn = c_m4[0][0],c_m4[0][1],c_m4[1][0],c_m4[1][1]\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1score = 2 * (recall * precision) / (recall + precision)\n",
    "print(\"recall = \",recall)\n",
    "print(\"precision = \", precision)\n",
    "print(\"F1_score = \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.09      0.17       974\n",
      "         1.0       0.91      1.00      0.95      8615\n",
      "\n",
      "    accuracy                           0.91      9589\n",
      "   macro avg       0.92      0.55      0.56      9589\n",
      "weighted avg       0.91      0.91      0.87      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predKNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)iyi\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)kötü\n",
      "[0.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzel\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)çirkin\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)f\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model5.predict(count_vect.transform([yorum])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model6 = MultinomialNB()\n",
    "model6.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predMNB = model6.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  96  878]\n",
      " [   0 8615]]\n"
     ]
    }
   ],
   "source": [
    "c_m5 = confusion_matrix(y_test,predMNB)\n",
    "print(c_m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9084367504432161"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predMNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.09856262833675565\n",
      "precision =  1.0\n",
      "F1_score =  0.1794392523364486\n"
     ]
    }
   ],
   "source": [
    "tp,fn,fp,tn = c_m5[0][0],c_m5[0][1],c_m5[1][0],c_m5[1][1]\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1score = 2 * (recall * precision) / (recall + precision)\n",
    "print(\"recall = \",recall)\n",
    "print(\"precision = \", precision)\n",
    "print(\"F1_score = \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.18       974\n",
      "         1.0       0.91      1.00      0.95      8615\n",
      "\n",
      "    accuracy                           0.91      9589\n",
      "   macro avg       0.95      0.55      0.57      9589\n",
      "weighted avg       0.92      0.91      0.87      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predMNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)iyi\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)kötü\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)güzl\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)berbat\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)iğrenç\n",
      "[1.]\n",
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız)f\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model6.predict(count_vect.transform([yorum])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
